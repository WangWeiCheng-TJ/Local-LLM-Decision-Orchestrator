# Job Hunting Season 2: Agentic Career Orchestrator 
#### An ROI-Driven Multi-Agent System
> **Current Status:** V2.2 Design Phase (Architecture Validated / Implementation In Progress)
> **Role:** Research Pilot for [Physically-Aware Synthetic Surveillance Data]

## ğŸ¯ Motivation

The primary motivation behind this project is to solve the extremely low signal-to-noise ratio in the current job market and the unsustainable time cost of high-quality applications.

In job hunting, one must sift through hundreds of job descriptions to find the few that match complex constraints (e.g., visa rules, tech stack compatibility, remote work policies). Traditional keyword search fails to capture these semantic nuances. For example, a position that requires computer vision experience could drown in the title "Machine Learning Engineer". Manually parsing hundreds of JDs to find the few that align with specific constraints (e.g., Privacy-Preserving AI, European Visa sponsorship) is a exhausting process that is an inefficient process that drains cognitive resources.

Furthermore, effective job hunting requires more than just reading; it demands **verification** (checking market salary, validating research alignment), **reflection** (comparing against past applications to avoid repeated mistakes), and **strategic execution** (prioritizing high-ROI opportunities and allocating effort efficiently). 


This project is to build an ROI-Driven Agentic System that automates the "low-level filtering" and "strategic intelligence gathering." This ensures that the human candidate can allocate their limited bandwidth exclusively to high-leverage opportunities, shifting focus from searching to crafting the perfect application.


**Research Context:**  
This project also serves as the architectural pilot for **Real-World Data-Driven Synthetic Surveillance Dataset Generation Pipeline**. By treating video generation models and task-specific LoRAs as "Agents," the future research aims to leverage this same agentic workflow to significantly improve efficiency and reduce computational costs in synthetic data generation.

---

## ğŸ“– Introduction

This project implements a Multi-Agent RAG Orchestrator with a dynamic Mixture-of-Advisors (MoA) pattern, where a Router Agent activates specialized LLM-based experts per JD and aggregates their assessments into strategic decisions. 

Unlike infra-level sparse Mixture-of-Experts (MoE) models with shared parameters inside a single network, each advisor here is an independent agent with its own prompt and memory, coordinated through orchestration rather than low-level model routing.

### ğŸš€ System Evolution: From V1 to V2.1
While V1 follows a predefined routine to analyze JDs, V2.1 introduces a decentralized Multi-Agent Architecture designed for strategic resource allocation.

The core evolution lies in moving from "1-to-1 Analysis" to "1-to-Many Strategy."

#### V1 (Legacy): A Rigid "Smart Filter"
   - **Fixed Linear Protocol**:<br> Processed data under a hard-coded procedure (Step A â†’ B â†’ C) regardless of the job context, lacking the autonomy to activate specific tools or skip unnecessary steps.
   - **Isolated & Internal**: <br>Relied solely on local text comparison; blind to external market realities (e.g., actual salary data, active research groups).
   - **Siloed Execution**: <br>Treated every JD as an independent event, lacking the ability to prioritize based on relative ROI.

#### V2.2 (Current): An Active "Strategic Commander"

This upgrade transforms the system from a passive analyzer to an active decision orchestrator, executing a 4-step OODA loop:

- **Reason (Dynamic Mixture-of-Advisors (MoA))**:  
  Introduces a Router Agent that dynamically assembles an Expert Council based on the JD's nature. For example, a "Senior Research Scientist" role triggers the Academic Analyst (evaluating research alignment) and the Engineering Lead (evaluating technical depth and team fit), while a startup role may additionally trigger the Startup Scout (equity/risk).

- **Perceive (Tool-Augmented)**:  
  Breaks the "internal bubble" by autonomously verifying salaries and retrieving relevant arXiv papers or team signals to ground analysis in external reality.

- **Plan (MoA Advisory Battle Plans)**:  
  Replaces generic feedback with concrete Battle Plans (e.g., "Fixing this self-supervised learning gap unlocks 15 positions"), aggregating multiple advisorsâ€™ perspectives into a single strategic recommendation rather than relying on a single all-purpose prompt.

- **Act (Hard Triage on Constraints)**:  
  Actively rejects non-viable roles (e.g., visa infeasibility, location/compensation mismatch, PhD relevance constraints) before they consume human attention or additional compute.

   

All core document storage (CVs, personal databases) remains **locally managed** via ChromaDB to maintain a structured local archive of user's career data, while the cloud API is used solely for reasoning tasks with sanitized inputs.

---



## ğŸ—ï¸ System Architecture

```mermaid
graph TD
    %% === å…¨åŸŸ Council è³‡æºæ±  (MoA) ===
    subgraph Pool ["ğŸ›ï¸ The Reviewer Council Pool (MoA)"]
        direction LR
        E1["ğŸ‘” HR Gatekeeper<br/>(Culture Fit, Soft Skills & Red Flags)"]:::council
        E2["âš™ï¸ Tech Lead<br/>(Tech Stack Depth & Hard Skills)"]:::council
        E3["â™Ÿï¸ Strategist<br/>(ROI, Tax, Location Tier & Stability)"]:::council
        E4["ğŸ›‚ Visa Officer<br/>(Work Permit & Legal Feasibility)"]:::council
        E5["ğŸ”¬ Academic<br/>(Pubs, Research Impact & Innovation)"]:::council
        E6["ğŸ—ï¸ Architect<br/>(Scalability, Cloud & Prod-Readiness)"]:::council
        E7["ğŸ¦ Leadership<br/>(Mentorship & Cross-functional Influence)"]:::council
        E8["ğŸš€ Startup Vet<br/>(Equity, Risk & Multi-tasking)"]:::council
    end
    
    %% === LEVEL 0: å±¥æ­·è»ç«åº« ===
    subgraph L0 ["Level 0: Pre-processing"]
        ResumeDB[("ğŸ—„ï¸ Resume Vector DB")]:::db
        PersonalDB[("ğŸ—„ï¸ Personal Vector DB")]:::db
        IndexerCV["ğŸ¤– Indexer Agent"]:::agent
        IndexerPK["ğŸ¤– Indexer Agent"]:::agent
        
        ResPDFs --> IndexerCV --> ResumeDB
        AllFiles --> IndexerPK --> PersonalDB


    end

    %% === Phase 1: æˆ°å ´æƒ…å ± ===
    subgraph P1 ["Phase 1: Intelligence Gathering"]
        Parser["JD Parser"]:::agent --> RawText[("ğŸ“„ Raw Text")]
        RawText --> Tools["ğŸŒ External Tools"]:::agent
        RawText & Tools --> Dossier["ğŸ—‚ï¸ Enriched Dossier"]:::doc
    end

    %% === Phase 2: æª¢å‚·åˆ†é¡ ===
    subgraph P2 ["Phase 2: Intelligent Triage"]
        Dossier --> Triage["ğŸ¥ Triage Agent <br/> Hard Constraints Check(Visa)"]:::agent
        PersonalDB -.-> Triage["ğŸ¥ Triage Agent <br/> Hard Constraints Reject(Visa/PhD)"]
     
        Triage -- "âŒ Reject" --> RejectLog["ğŸ“ Rejected_Log.json<br/>(Brief Reason)"]:::output
        RejectLog --> Bin["ğŸ“‚ /99_Trash"]

        Triage -- "âœ… Pass" --> Metadata["Metadata<br/>(Role/Domain)"]:::doc
        Metadata --> Router
    end

    %% === Phase 3 æµç¨‹ ===
    subgraph P3 ["Phase 3: Expert Diagnosis"]
        Metadata --> Router["ğŸ”€ Council Router"]:::agent
        Dossier --> Router

        Router --> |"Calls"| ActivePanel
        
        subgraph ActivePanel ["ğŸ§‘â€âš–ï¸ Active Panel(Same Instance, Different Modes)"]
            direction TB
            Panel1["ğŸ” Skill Analysis Mode"]:::panel
            Panel2["ğŸ§  Gap & Effort Analysis Mode"]:::panel
            Panel1 --> |"Requirement Context"|Panel2
        end
        
        Dossier --> Panel2
        Panel1 --> |"Search Queries"| Retriever["ğŸ¤– Retriever"]:::agent

        Retriever <-.-> |"Evidence/Chunks"| PersonalDB
        Retriever <-.-> |"Reusable Sentences"| ResumeDB
        Retriever --> |"Retrieved Material"| Panel2

        Panel2 --> Out["ğŸ“Š Strategy Data (Blueprint)"]:::output
    end

    %% === Phase 4: æˆ°ç•¥åœ°åœ– ===
    subgraph P4 ["Phase 4: Strategic Command"]
        Out & Metadata --> MapEngine["ğŸ—ºï¸ Correlation Engine"]:::agent
        MapEngine --> VisualMap["Visual Correlation Map"]
        VisualMap --> TheGeneral["ğŸ‘® Strategist"]:::agent
        TheGeneral --> BattlePlan["ğŸ“Š ImpactReport"]:::output
    end

    %% === Human Loop ===
    BattlePlan --> UserCheck{"ğŸ‘¤ User Review"}
    UserCheck -- "Approve" --> BriefingAgent["âš¡ Briefing Agent"]:::agent

    UserCheck -- "Modify / Veto" --> Refine["Adjust Plan"]
    Refine --> BriefingAgent

    %% === Phase 5: æˆ°è¡“åŸ·è¡Œ ===
    subgraph P5 ["Phase 5: Campaign Output"]
    Editor["ğŸ‘¨â€ğŸ”¬ Editor<br/>(Orgainize Suggestions, Conflict Resolution)"]:::council

        BriefingAgent -->|"Cluster Context"| Panel3["ğŸ‘¨â€ğŸ”¬ Advisor Mode"]:::panel
        PersonalDB -.->|"Personal Knowledge"| Panel3["ğŸ‘¨â€ğŸ”¬ Advisor Mode"]:::panel
        ResumeDB -.->|"Past Resume"| Panel3["ğŸ‘¨â€ğŸ”¬ Advisor Mode"]:::panel
        
        Panel3["ğŸ‘¨â€ğŸ”¬ Advisor Mode"] --> Editor["âœï¸ Editor"]:::council

        Editor --> OutputA["ğŸ“‚ /01_Campaign_Privacy<br/>- ğŸ“„ Strategy_Guide.md (Advice: Insert X objective in project A)<br/>- ğŸ“‚ 10 Target JDs"]:::output
        Editor --> OutputB["ğŸ“‚ /02_Campaign_Infra<br/>..."]:::output
    end

    %% === æ¨£å¼å®šç¾© (è·¨æ¨¡å¼ç›¸å®¹) ===
    classDef council fill:#e1bee7,stroke:#4a148c,color:#000;
    classDef panel fill:#fff9c4,stroke:#fbc02d,color:#000;
    classDef agent fill:#c8e6c9,stroke:#2e7d32,color:#000;
    classDef db fill:#bbdefb,stroke:#1565c0,color:#000;
    classDef doc fill:#f5f5f5,stroke:#616161,color:#000;
    classDef output fill:#ffccbc,stroke:#d84315,color:#000;
``` 



## ğŸš€ Key Features
#### 1. The Arsenal: Semantic Resume Indexing (Level 0)
   * **Pre-processing Agent:** An asynchronous `Indexer Agent` breaks down the user's Master CV and Papers into semantic fragments tagged by attributes (e.g., `#Privacy`, `#ComputerVision`, `#Leadership`).
   * **Vector-Based Retrieval:** Uses **ChromaDB** to retrieve only the relevant "skills blocks" needed for a specific JD, preventing context window pollution with irrelevant experiences.

#### 2. Tool-Augmented Intelligence (Phase 1)
   * **External Grounding:** The system actively gathers external context to "comprehend" the JD before analysis.
   * **Active Tools:**
      - **Salary Validator:** Queries external sources (mock Levels.fyi/Glassdoor) to verify if the ROI justifies the effort.
      - **Team Investigation:** Searches arXiv/Google Scholar to verify if the hiring team is scientifically active.

#### 3. Intelligent Triage & Gatekeeping (Phase 2)
   * **Hard Constraints Check:** A strict "Gatekeeper Agent" enforces physical survival constraints first.
   * **Filtering Logic:** Automatically rejects roles based on **Visa Sponsorship** feasibility (EU Work Permit), **PhD Relevance**, and **Expertise mis-Matched** constraints.
   * **Impact:** Reduces compute costs and cognitive load by ensuring only "playable" opportunities enter the analysis pipeline.

#### 4. Dynamic Mixture-of-Agents (Phase 3)
* **Router-Based Diagnosis**: Instead of a single generic "Analysis Prompt", a Router Agent activates a small set of specialized reviewers based on the JD's domain and seniority.
    Example of the Council Members:
    - **Academic Analyst**: For researchâ€‘heavy roles (e.g., Research Scientist; focus: publication track record, topic alignment, lab/team fit).
    - **Engineering Lead**: For ML/Software roles (focus: deployment readiness, C++/systems skills, production constraints).
    - **Startup Scout**: For earlyâ€‘stage companies (focus: equity vs. cash tradeâ€‘offs, runway, product risk, role ambiguity).
* **Benefit**: Produces domainâ€‘specific, roleâ€‘aware gap analysis instead of generic career advice, by routing each JD to the most relevant advisors rather than treating all roles with a single monolithic prompt.

Architecturally this behaves like a Mixtureâ€‘ofâ€‘Advisors (MoA) in a multiâ€‘agent system, not an infraâ€‘level sparse MoE model.

        
#### 5. Strategic Clustering (Phase 4 - The War Room)
   * **Correlation Engine:** Cross validate JDs to compute the correlations between to help prioritise applications.
   * **Battle Plans:** Instead of 15 separate resume edits, the system generates a unified strategy (e.g., *"Injecting [Self-Supervised Learning] insights into Project A will have positive impact on these 12 JDs"*).

#### 6. Advisory Briefing Agent (Phase 5)
   * **Strategy over Generation:** The system acts as a **Chief of Staff**, delivering a `Strategy_Guide.md` ("The What and Why") rather than just ghostwriting the resume ("The How").
   * **Actionable Insights:** Provides specific directives like *"Highlight Paper X to counter the lack of Spark experience,"* preserving the user's authentic voice.


## âš¡ Quick Start & Setup

1. Environment Configuration (`.env`)
Create a `.env` file in the root directory. This is crucial for linking your local files (e.g., Google Drive) to the Docker container. (refer to .env_example)

2. Directory Setup
Refer to [Data Structure](#-data-structure)

3. Launch the System
Start the Docker container in detached mode: ```docker-compose up -d --build```

4. Memory Injection (Initialization)

    **Step 1**: <br>Run these once initially, or whenever you update your Resume/AboutMe.md.
    * Ingest Personal Knowledge (Identity):<br> ```docker-compose run --rm orchestrator python src/data/ingest.py``` <br> Reads ```data/raw/AboutMe.md``` and whatever files in ```data/raw/``` to build the agent's core understanding of YOU.
    * Ingest Battle History (Experience):<br> ```docker-compose run --rm orchestrator python src/ingest_history.py``` <br> Scans your ```LOCAL_PATH_TO_...``` folders to index past applications for the "War Room" recall feature.

    **Step 2**: The Hunt (Routine) <br>
    Execute this loop when adding new JDs.
    * Feed: Drop new JD PDFs (or images) into ```data/jds/```.
    * Hunt: Run the main orchestrator.<br> ```docker-compose run --rm orchestrator python src/main.py``` 
    * Review: Check the output in ```data/reports/```:
        * ```Strategic_Leaderboard.csv```: Prioritize applications.
        * ```Analysis_*.md```: Read detailed strategy & warnings.

    **Step 3**: Post-Battle Maintenance<br> When you receive an outcome (Reject/Interview):
    * Move the JD folder from Ongoing to Rejected (on your local drive).
    * Add an ```result.txt``` or ```reject_letter.txt``` inside the folder.
    * Run Ingest History again to update the agent's memory:<br>```docker-compose run --rm orchestrator python src/ingest_history.py```

## ğŸ› ï¸ Tech Stack
* **Orchestration:** Python, Google Generative AI SDK (Gemini API)
* **Model:** Gemma-3-27b
* **Vector Store:** ChromaDB (Using default `all-MiniLM-L6-v2` for local embeddings)
* **Environment:** Python 3.11 / Docker

## ğŸ“‚ Data Structure
The system automatically manages raw inputs and cached outputs:

```text
data/
â”œâ”€â”€ chroma_db/            # Vector Database (User Profile & History Index)
â”œâ”€â”€ raw/                  # Personal Knowledge Base
â”‚   â”œâ”€â”€ AboutMe.md        # Dynamic User Values (Money, Visa, Location)
â”‚   â””â”€â”€ cv_papers.pdf     # Resume & Academic Papers
â”œâ”€â”€ jds/                  # Input: New JDs to Analyze
â”‚   â”œâ”€â”€ position_A.pdf
â”‚   â””â”€â”€ position_A.txt    # Cached OCR/Text Result
â”œâ”€â”€ reports/              # Output: Analysis Reports
â”‚   â”œâ”€â”€ Analysis_A.md
â”‚   â””â”€â”€ Strategic_Leaderboard.csv      
â””â”€â”€ history/              # Historical Battle Data
    â”œâ”€â”€ ongoing/          # Active Applications
    â””â”€â”€ rejected/         # Past Failures (For Post-Mortem Recall)
```

## ğŸ”® Future Roadmap: Automated Optimization (V3.0)
Currently, the system serves as an intelligent advisor that *recalls* history. The V3.0 objective is to implement **Reinforcement Learning (RL)** logic to let the agent *learn* from history independently.

### Planned Capabilities
* **Global Trend Analysis (Beyond One-to-One):**
    * Instead of just recalling a specific past job, the agent will analyze aggregate data (e.g., "You have an 85% rejection rate when applying to 'FinTech' roles with 'CV Version B'. Stop doing that.")
* **Automated A/B Testing:**
    * Systematically generates two different "Persona Pitches" for similar roles, tracks the callback rate, and automatically updates the `Master CV` strategy weights based on the winner.
* **ATS Trap Detection:**
    * Reverse-engineers the "Black Box" of ATS systems by identifying common keyword patterns in `Auto-Reject` outcomes across different companies.
    
---
*This project is part of a broader research initiative on Agentic AI workflows for Data Synthesis.*