import os
import json
import re
import time
import typing
import google.generativeai as genai
from tqdm import tqdm
from termcolor import colored
from dotenv import load_dotenv
import pydantic

# ==============================================================================
# Tagged Protocol Parser (The New Secret Sauce)
# ==============================================================================
load_dotenv()
TPM_SAFE_LIMIT = os.getenv("TPM_SAFE_LIMIT", 13000)

import re

def parse_gemma_tags(raw_text: str) -> dict:
    """
    [Universal Parser V4] 
    Ëá™ÂãïË≠òÂà• Phase 1 (Skill), Phase 2 (Gap), Phase 3 (Advisor) ÁöÑÊ®ôÁ±§ÂÖßÂÆπÔºå
    ‰∏¶Âª∫ÊßãÂ∞çÊáâÁöÑÂ∑¢ÁãÄÁµêÊßã (Nested Objects) ‰ª•Á¨¶Âêà Pydantic Schema„ÄÇ
    """
    if not raw_text or not isinstance(raw_text, str):
        return None

    # 1. ÊäìÂèñÊâÄÊúâ @@@ ÂçÄÂ°ä
    blocks = re.findall(r'@@@(.*?)@@@', raw_text, re.DOTALL)
    if not blocks:
        # Fallback: ÂòóË©¶Áõ¥Êé•Êäì JSON ÊàñÂÖ∂‰ªñÊ†ºÂºè (Ë¶ñÊÉÖÊ≥ÅÊì¥ÂÖÖ)
        return None

    results = []
    detected_type = "SKILL" # È†êË®≠È°ûÂûã

    for block in blocks:
        def extract(key_pattern):
            # ÊîØÊè¥Â§öÁ®Æ aliasÔºå‰æãÂ¶Ç STRATEGY|PLAN
            pattern = fr'(?:{key_pattern}):\s*(.*?)(?=\n[A-Z_]+:|$)'
            match = re.search(pattern, block, re.IGNORECASE | re.DOTALL)
            if match and match.group(1) is not None:
                return match.group(1).strip()
            return ""

        # --- 2. ÁâπÂæµÂÅµÊ∏¨ (Feature Detection) ---
        # Ê†πÊìöÂçÄÂ°äÂÖßÂê´ÊúâÁöÑÊ®ôÁ±§‰æÜÊ±∫ÂÆöÈÄôÊòØ‰∏ÄÁ≠Ü‰ªÄÈ∫ºË≥áÊñô
        
        # [Phase 2 Detection] ÊòØÂê¶ÂåÖÂê´ EFFORT Êàñ STRATEGY?
        if "EFFORT" in block or "STRATEGY" in block or "EVIDENCE" in block:
            detected_type = "GAP"
            
            # Âª∫Êßã Phase 2 ÁöÑÂ∑¢ÁãÄÁµêÊßã (GapAnalysisItem)
            item = {
                "topic": extract("TOPIC|SKILL"),
                "evidence_in_personal_db": {
                    "status": extract("EVIDENCE_STATUS|STATUS") or "NOT_FOUND",
                    "evidence_snippet": extract("EVIDENCE|PROOF") or "No evidence found."
                },
                "resume_reusability": {
                    "status": extract("REUSABILITY_STATUS|REUSABILITY") or "NO_MATCH",
                    "closest_existing_bullet": extract("BULLET|CLOSEST_BULLET")
                },
                "effort_assessment": {
                    "level": extract("EFFORT_LEVEL|EFFORT") or "HIGH",
                    "strategy": extract("STRATEGY|PLAN") or "Review required.",
                    "estimated_action": extract("ACTION|ESTIMATED_ACTION") or "Update resume."
                }
            }
            results.append(item)

        # [Phase 3 Detection] ÊòØÂê¶ÂåÖÂê´ RATIONALE Êàñ ADVICE?
        elif "RATIONALE" in block or "ACTIONABLE_STEP" in block:
            detected_type = "ADVISOR"
            
            item = {
                "topic": extract("TOPIC|FOCUS_AREA"),
                "rationale": extract("RATIONALE|REASONING"),
                "actionable_step": extract("ACTIONABLE_STEP|ACTION|INSTRUCTION"),
                "priority": extract("PRIORITY") or "MEDIUM"
            }
            results.append(item)

        # [Phase 1 Default] È†êË®≠ÁÇ∫ Skill Extraction
        else:
            detected_type = "SKILL"
            
            # Âª∫Êßã Phase 1 ÁöÑÁµêÊßã (SkillItem)
            item = {
                "topic": extract("TOPIC"),
                "priority": extract("PRIORITY") or "MUST_HAVE",
                "analysis": {
                    "hidden_bar": extract("HIDDEN_BAR|HBAR|IMPLICIT_REQUIREMENT") or "None detected.",
                    "quote_from_jd": extract("QUOTE|SOURCE") or "Contextual."
                }
            }
            results.append(item)

    # 3. Ê†πÊìöÂÅµÊ∏¨Âà∞ÁöÑÈ°ûÂûãÂõûÂÇ≥Ê≠£Á¢∫ÁöÑ Root Key
    if detected_type == "GAP":
        return {"gap_analysis": results}
    elif detected_type == "ADVISOR":
        return {"strategic_advice": results}
    else:
        return {"required_skills": results}

# ==============================================================================
# Helper Functions: JSON Extraction & Repair
# ==============================================================================

def extract_json_from_text(text: str) -> str:
    if not text: return "" # ÂÆâÂÖ®Èò≤Á∑ö
    match = re.search(r'```json\s*(.*?)```', text, re.DOTALL)
    if match: return match.group(1).strip()
    
    start, end = text.find('{'), text.rfind('}')
    if start != -1 and end != -1: return text[start : end + 1]
    return text.strip() # Ê≠§ÊôÇ text ÂøÖÁÇ∫Â≠ó‰∏≤

def aggressive_fix_json(bad_json: str) -> dict:
    try:
        fixed = re.sub(r',\s*}', '}', bad_json)
        fixed = re.sub(r',\s*]', ']', fixed)
        return json.loads(fixed)
    except: pass
    try:
        if bad_json.count('{') > bad_json.count('}'):
            return json.loads(bad_json + '}' * (bad_json.count('{') - bad_json.count('}')))
        if bad_json.count('[') > bad_json.count(']'):
            return json.loads(bad_json + ']' * (bad_json.count('[') - bad_json.count(']')))
    except: pass
    return None

def normalize_structure(data):
    if not isinstance(data, (dict, list)): return data
    
    # Â¶ÇÊûú parse_gemma_tags Â∑≤Á∂ìÂõûÂÇ≥‰∫ÜÊ≠£Á¢∫ÁöÑ Dict ÁµêÊßãÔºåÁõ¥Êé•ÂõûÂÇ≥
    if isinstance(data, dict) and ("required_skills" in data or "gap_analysis" in data):
        return data

    # ÈÄôË£°‰øùÁïô‰Ω†‰πãÂâçÁöÑ‰øÆÂæ©ÈÇèËºØ (Áï•ÔºåÂ∑≤Êï¥ÂêàÈÄ≤ parse_gemma_tags)
    return data

# ==============================================================================
# Main Class: SmartModelGateway
# ==============================================================================

class SmartModelGateway:
    def __init__(self, config):
        self.config = {}
        if isinstance(config, dict):
            self.config = config
        elif isinstance(config, str):
            if os.path.isfile(config):
                tqdm.write(colored(f"  üìÇ Loading config: {config}", "cyan"))
                with open(config, 'r') as f: self.config = json.load(f)
            else:
                # Ë™çÂèØÊòØ API Key (‰∏çÂç∞Âá∫‰æÜ)
                self.config = {"api_key": config}

        if "api_key" not in self.config:
            raise ValueError("‚ùå Missing 'api_key' in SmartModelGateway config.")

        genai.configure(api_key=self.config["api_key"])
        
        lt_name = os.getenv("MODEL_LT_NAME", "gemini-1.5-flash")
        main_name = os.getenv("MODEL_NAME", "gemma-3-27b-it")
        tqdm.write(colored(f"  ü§ñ SmartModelGateway Init: LT={lt_name}, Main={main_name}", "cyan"))
        
        self.flash_model = genai.GenerativeModel(lt_name)
        self.gemma_model = genai.GenerativeModel(main_name)

    def generate(self, prompt: str, *args, **kwargs) -> dict:
        """
        [Expert Council Edition] 
        Êï¥Âêà: 14k TPM Âì®ÂÖµ„ÄÅPydantic/Function ÈõôÊ®°È©óË≠â„ÄÅGemma/Flash Ëá™ÂãïÂ∞éÊµÅ„ÄÇ
        """
        # 1. ÂΩàÊÄßÂèÉÊï∏ÊäìÂèñ
        # ÊîØÊè¥ schema=..., schema_model=..., Êàñ‰ΩçÁΩÆÂèÉÊï∏ args[0]
        schema = kwargs.get('schema') or kwargs.get('schema_model')
        if not schema and len(args) > 0:
            schema = args[0]
            
        # ÊîØÊè¥ use_gemma=..., Êàñ‰ΩçÁΩÆÂèÉÊï∏ args[1]
        use_gemma_req = kwargs.get('use_gemma', True)
        if not use_gemma_req and len(args) > 1:
            use_gemma_req = args[1]

        # 2. Token Ë®∫Êñ∑Ëàá TPM Âì®ÂÖµ
        try:
            # ‰ΩøÁî® Flash ÈÄ≤Ë°åÁ≤æÁ¢∫Ë®àÊï∏ (‰∏çË®àÂÖ• Gemma ÁöÑ TPM È°çÂ∫¶)
            token_count = self.flash_model.count_tokens(prompt).total_tokens
        except:
            token_count = len(prompt) // 4 

        # Ë®≠ÂÆö TPM ÂÆâÂÖ®Ê∞¥‰ΩçÁÇ∫ 14,000 (È†êÁïô 1,000 Áµ¶Ëº∏Âá∫)
        # TPM_SAFE_LIMIT = 13000 
        env_limit = os.getenv("TPM_SAFE_LIMIT", "14000")
        tpm_limit = int(env_limit)
        actual_use_gemma = use_gemma_req
        
        
        # Ëá™ÂãïÂàÜÊµÅÈÇèËºØ
        if use_gemma_req and token_count > (tpm_limit - 1000):
            print("171", tpm_limit, use_gemma_req, token_count)
            input()
            actual_use_gemma = False
            tqdm.write(colored(f"  ‚ö†Ô∏è TPM Sentinel: Prompt size ({token_count}) approaching {tpm_limit//1000}k limit. Auto-switching to Flash.", "yellow"))
        elif token_count > 5000:
            # Âç≥‰ΩøÊ≤íÁ†¥‰∏äÈôêÔºåËã•Ë∂ÖÈÅé 5k ‰πüÁµ¶‰∏ÄÂÄãÊèêÁ§∫ (ÂçîÂä©Ë®∫Êñ∑ÊòØÂê¶ÊúâË≥áÊñôÊ¥©Êºè)
            tqdm.write(colored(f"  üîç Diagnostic: Large prompt detected ({token_count} tokens).", "magenta"))

        model = self.gemma_model if actual_use_gemma else self.flash_model
        
        # 3. ÈõôÊ®°ÂºèÈ©óË≠âÊ†∏ÂøÉÔºöËß£Ê±∫ 'BaseModel.__init__() takes 1 positional argument but 2 were given'
        def run_validation(validator, target_data):
            """
            ÈÅ©ÈÖçÂô®ÔºöËá™ÂãïÂà§Êñ∑ÊòØ Pydantic Model È°ûÂà•ÈÇÑÊòØÊôÆÈÄöÈ©óË≠âÂáΩÂºè„ÄÇ
            """
            # Ê™¢Êü•ÊòØÂê¶ÁÇ∫ Pydantic Model È°ûÂà•
            is_pydantic = isinstance(validator, type) and issubclass(validator, pydantic.BaseModel)
            
            try:
                if is_pydantic:
                    # Ê®°Âºè A: Pydantic È°ûÂà•‰ΩøÁî®Ëß£ÂåÖÂÇ≥ÂÖ• (Êàñ‰ΩøÁî® model_validate)
                    # ÈÄôËÉΩÈÅøÂÖçÂ∞áÊï¥ÂÄã dict Áï∂ÊàêÁ¨¨‰∏ÄÂÄã positional argument ‰∏üÈÄ≤ __init__
                    validator(**target_data) 
                    return True, ""
                else:
                    # Ê®°Âºè B: ÊôÆÈÄöÈ©óË≠âÂáΩÂºè (Â¶Ç validate_council_skill) Áõ¥Êé•Êï¥ÂåÖÂÇ≥ÂÖ•
                    validator(target_data)
                    return True, ""
            except Exception as e:
                return False, str(e)

        # --- 4. Êô∫ËÉΩÊ¥æÁôºÂô® (Smart Dispatcher) ---
        def validate_dispatcher(data):
            if not schema: return True, ""
            
            # [Á≠ñÁï• A] ÂÑ™ÂÖàÂòóË©¶„ÄåÊï¥ÂåÖÈ©óË≠â„Äç (Root Validation)
            # ÈÅ©Áî®ÊñºÔºö‰Ω†ÂÇ≥ÂÖ•‰∫Ü SkillExtractionReport, GapAnalysisReport Á≠âÂÆåÊï¥ÁµêÊßã
            is_root_ok, root_err = run_validation(schema, data)
            if is_root_ok:
                return True, ""

            # [Á≠ñÁï• B] Â¶ÇÊûúÊï¥ÂåÖÂ§±ÊïóÔºåÊ™¢Êü•ÊòØÂê¶ÁÇ∫„ÄåÂåÖË£ùÁµêÊßã„Äç‰∏¶ÂòóË©¶„ÄåÈÄêÈ†ÖÈ©óË≠â„Äç (Item Validation)
            # ÈÅ©Áî®ÊñºÔºö‰Ω†ÂÇ≥ÂÖ•‰∫Ü SkillItemÔºå‰ΩÜË≥áÊñôË¢´ÂåÖÂú® {"required_skills": [...]} Ë£°Èù¢
            if isinstance(data, dict):
                target_keys = ["required_skills", "gap_analysis", "strategic_advice"]
                
                for key in target_keys:
                    if key in data and isinstance(data[key], list):
                        # ÁôºÁèæÂåÖË£ùÂ±§ÔºåÈÄ≤ÂÖ•ÊãÜÂåÖÊ®°Âºè
                        for idx, item in enumerate(data[key]):
                            # ÈÄôË£°ÊòØÁî®ÂéüÊú¨ÁöÑ schema ÂéªÈ©óË≠âÂàóË°®Ë£°ÁöÑÊØè‰∏ÄÂÄã item
                            is_item_ok, item_err = run_validation(schema, item)
                            if not is_item_ok:
                                # ÈÄôË£°ÂõûÂÇ≥ Item Á¥öÂà•ÁöÑÈåØË™§ÔºåÊúÉÊØî Root ÈåØË™§Êõ¥Á≤æÊ∫ñ
                                return False, f"Item {idx} in '{key}' failed: {item_err}"
                        
                        # Â¶ÇÊûúÊâÄÊúâ Items ÈÉΩÈÄöÈÅéÔºå‰ª£Ë°®ÈÄôÊòØ Item Schema Ê®°ÂºèÔºåÈ©óË≠âÊàêÂäü
                        return True, ""

            # Â¶ÇÊûúÊó¢‰∏çÊòØÊï¥ÂåÖÈÄöÈÅéÔºå‰πü‰∏çÊòØÂåÖË£ùÁµêÊßãÂïèÈ°åÔºåÈÇ£Â∞±ÂõûÂÇ≥ÊúÄÂéüÂßãÁöÑ Root ÈåØË™§
            return False, f"Validation failed: {root_err}"

            # 2. ÂñÆ‰∏ÄÁâ©‰ª∂Ê®°Âºè (Fallback)
            # Â¶ÇÊûú data ‰∏çÊòØÂåÖË£ùÁµêÊßãÔºåÊàñÊòØÊâæ‰∏çÂà∞‰∏äËø∞ keysÔºåÂòóË©¶Áõ¥Êé•È©óË≠â
            return run_validation(schema, data)

        # 5. ÈÖçÁΩÆËàáÂü∑Ë°å
        gen_config = genai.types.GenerationConfig(
            temperature=0.2 if actual_use_gemma else 0.1
        )

        return self._generate_with_retry_logic(
            model=model,
            prompt=prompt,
            validator_func=validate_dispatcher,
            max_retries=3,
            generation_config=gen_config
        )


    def _generate_with_retry_logic(self, model, prompt, validator_func, max_retries, generation_config=None):
        current_prompt = prompt
        last_result, last_error_msg = None, "Unknown Error"
        
        log_dir = "data"
        os.makedirs(log_dir, exist_ok=True)
        log_path = os.path.join(log_dir, "debug_gemma.log")

        for attempt in range(max_retries + 1):
            try:
                response = model.generate_content(current_prompt, generation_config=generation_config)
                raw_text = response.text if response.text else "[EMPTY]"
                
                tqdm.write(colored(f"\nüëÄ [DEBUG] Attempt {attempt+1}:", "cyan"))
                tqdm.write(colored(raw_text[:150].replace('\n', ' ') + "...", "white", attrs=['dark'])) 

                with open(log_path, "a", encoding="utf-8") as f:
                    f.write(f"\n\n{'='*20} ATTEMPT {attempt+1} ({time.strftime('%H:%M:%S')}) {'='*20}\n")
                    f.write(f"--- RAW RESPONSE ---\n{raw_text}\n{'='*50}\n")

                # --- Ê†∏ÂøÉËß£ÊûêÂàÜÊîØ ---
                if "@@@" in raw_text:
                    result_json = parse_gemma_tags(raw_text)
                    if not result_json: raise ValueError("Tag parsing failed (Blocks found but no fields)")
                else:
                    cleaned_text = extract_json_from_text(raw_text)
                    try:
                        result_json = json.loads(cleaned_text)
                    except:
                        result_json = aggressive_fix_json(cleaned_text)
                        if result_json is None: raise ValueError("JSON parse failed")

                result_json = normalize_structure(result_json)
                last_result = result_json
                
                is_valid, error_msg = validator_func(result_json)
                if is_valid:
                    if attempt > 0: tqdm.write(colored(f"  ‚ú® Repaired on attempt {attempt+1}", "yellow"))
                    return result_json
                
                last_error_msg = error_msg
                tqdm.write(colored(f"  ‚ö†Ô∏è Validation failed: {error_msg}", "light_red"))
                
                if attempt < max_retries:
                    wait_time = 20 * (attempt + 1)
                    current_prompt += f"\n\n[SYSTEM ERROR]: {error_msg}. Please fix this and follow the protocol."
                    tqdm.write(colored(f"  ‚è≥ Sleeping {wait_time}s...", "yellow"))
                    time.sleep(wait_time)

            except Exception as e:
                last_error_msg = str(e)
                tqdm.write(colored(f"  ‚ùå Error (Attempt {attempt+1}): {e}", "red"))
                if attempt < max_retries: time.sleep(20 * (attempt + 1))

        tqdm.write(colored(f"  üíÄ DEAD: {last_error_msg}", "red", attrs=['bold']))
        return {"error": "Max retries reached", "failure_reason": last_error_msg, "debug_dump": last_result}