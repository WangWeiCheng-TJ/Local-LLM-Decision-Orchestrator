# src/utils.py
import os
import glob
import re
import time
import json

import google.generativeai as genai 
from termcolor import cprint
from pypdf import PdfReader

import chromadb
from termcolor import cprint

CHROMA_PATH = os.getenv("CHROMA_DB_PATH", "/app/data/chroma_db")

def extract_text_from_pdf(filepath, model_name="gemini-1.5-flash"):
    """
    [æ–°å¢] é€šç”¨è®€å–å·¥å…·ï¼šå„ªå…ˆå˜—è©¦ pypdfï¼Œå¤±æ•—æˆ–å­—æ•¸å¤ªå°‘å‰‡è‡ªå‹•è½‰ OCR
    é€™æ¨£ ingest å’Œ scout éƒ½å¯ä»¥ç›´æ¥ import é€™å€‹å‡½å¼ã€‚
    """
    text = ""
    used_ocr = False
    filename = os.path.basename(filepath)

    # 1. å˜—è©¦ pypdf
    try:
        reader = PdfReader(filepath)
        for page in reader.pages:
            content = page.extract_text()
            if content: text += content + "\n"
    except Exception:
        pass 

    # 2. OCR Fallback (ç›´æ¥å‘¼å«åŒæª”æ¡ˆå…§çš„ gemini_ocr)
    if len(text.strip()) < 50:
        cprint(f"   ğŸ‘ï¸ [OCR Triggered] Content too short: {filename}", "cyan")
        # å‡è¨­ gemini_ocr å°±åœ¨é€™å€‹æª”æ¡ˆä¸‹é¢å®šç¾©å¥½äº†
        text = gemini_ocr(filepath, model_name=model_name)
        used_ocr = True
    
    return text, used_ocr

def identify_application_packet(folder_path):
    """
    æƒææŒ‡å®šè³‡æ–™å¤¾ï¼Œæ ¹æ“šæª”åé—œéµå­—è­˜åˆ¥ JD, CV, Cover Letter å’Œ Outcomeã€‚
    
    Args:
        folder_path (str): ç›®æ¨™è³‡æ–™å¤¾è·¯å¾‘
        
    Returns:
        dict: åŒ…å« 'jd', 'resume', 'cl', 'outcome' è·¯å¾‘çš„å­—å…¸
    """
    packet = {
        "jd": None,
        "resume": None,
        "cl": None,
        "outcome": None,
        "folder": folder_path
    }
    
    if not os.path.exists(folder_path):
        return packet

    # å–å¾—æ‰€æœ‰æª”æ¡ˆ (ä¸åŒ…å«å­ç›®éŒ„)
    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]
    
    for f in files:
        fname = f.lower()
        full_path = os.path.join(folder_path, f)
        
        # 1. è­˜åˆ¥ JD (å„ªå…ˆæ¬Šï¼šåªè¦æœ‰ jd, job å°±ä¸­)
        if not packet["jd"] and any(x in fname for x in ["jd", "job", "description", "vacancy", "role"]):
            packet["jd"] = full_path
            
        # 2. è­˜åˆ¥ Resume/CV
        elif not packet["resume"] and any(x in fname for x in ["resume", "cv", "curriculum"]):
            packet["resume"] = full_path
            
        # 3. è­˜åˆ¥ Cover Letter
        elif not packet["cl"] and any(x in fname for x in ["cl", "cover", "letter"]):
            packet["cl"] = full_path
            
        # 4. è­˜åˆ¥çµæœ (Outcome/Status)
        elif not packet["outcome"] and any(x in fname for x in ["outcome", "reject", "decision", "offer", "status", "result"]):
            packet["outcome"] = full_path

    return packet

def list_history_folders(base_path):
    """ åˆ—å‡ºè©²è·¯å¾‘ä¸‹æ‰€æœ‰çš„ç¬¬ä¸€å±¤å­è³‡æ–™å¤¾ """
    return [f.path for f in os.scandir(base_path) if f.is_dir()]

# --- [æ–°å¢] é€šç”¨ OCR å·¥å…· ---
def gemini_ocr(filepath, model_name="gemini-1.5-flash"):
    """
    é€šç”¨ OCR æ¨¡çµ„ï¼š
    1. ä¸Šå‚³æª”æ¡ˆ
    2. ç­‰å¾…è™•ç† (Polling)
    3. å‘¼å« Vision API è½‰æ–‡å­—
    
    é è¨­ä½¿ç”¨ Flash æ¨¡å‹ (é€Ÿåº¦å¿«ã€ä¾¿å®œã€Rate Limit é«˜)
    """
    cprint(f"   ğŸ‘ï¸ [Utils] å•Ÿå‹• Cloud OCR: {os.path.basename(filepath)}", "magenta")
    
    try:
        # 1. ä¸Šå‚³
        sample_file = genai.upload_file(path=filepath, display_name="OCR_Target")
        
        # 2. ç­‰å¾…è™•ç†
        while sample_file.state.name == "PROCESSING":
            time.sleep(1)
            sample_file = genai.get_file(sample_file.name)
        
        # 3. ç”Ÿæˆ
        model = genai.GenerativeModel(model_name)
        response = model.generate_content([sample_file, "Extract all text from this document accurately."])
        
        return response.text
    except Exception as e:
        cprint(f"   âŒ OCR å¤±æ•—: {e}", "red")
        return None
    
def clean_json_text(text):
    """
    å°ˆé–€ç”¨ä¾†æ¸…æ´— LLM åå›ä¾†çš„ JSON å­—ä¸²ã€‚
    å»é™¤ Markdown æ¨™è¨˜ (```json ... ```) å’Œå¤šé¤˜ç©ºç™½ã€‚
    """
    # 1. ç§»é™¤ ```json å’Œ ``` æ¨™è¨˜
    text = re.sub(r"```json\s*", "", text, flags=re.IGNORECASE)
    text = re.sub(r"```", "", text)
    
    # 2. æœ‰æ™‚å€™ LLM æœƒåœ¨ JSON å‰å¾ŒåŠ å»¢è©±ï¼Œå˜—è©¦æŠ“å‡º { ... } çš„éƒ¨åˆ†
    # ç°¡å–®çš„æ­£å‰‡è¡¨é”å¼å°‹æ‰¾æœ€å¤–å±¤çš„ {}
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if match:
        text = match.group(0)
        
    return text.strip()

def safe_generate_json(model, prompt, retries=3, delay=20, default_output=None):
    """
    é€™å°±æ˜¯ä½ çš„ã€Œé˜²å‘†é˜²è­·ç½©ã€ã€‚
    
    Args:
        model: Gemini model ç‰©ä»¶
        prompt: æç¤ºè©
        retries: é‡è©¦æ¬¡æ•¸ (é è¨­ 3 æ¬¡)
        delay: æ¯æ¬¡é‡è©¦ä¸­é–“ä¼‘æ¯å¹¾ç§’ (é è¨­ 2 ç§’)
        default_output: å¦‚æœå…¨å¤±æ•—ï¼Œè¦å›å‚³ä»€éº¼é è¨­å€¼ (é¿å… Crash)
    
    Returns:
        dict: è§£æå¥½çš„ JSON è³‡æ–™
    """
    for attempt in range(retries):
        try:
            # 1. ç™¼é€è«‹æ±‚
            response = model.generate_content(prompt)
            
            # 2. æ¸…æ´—æ–‡å­—
            cleaned_text = clean_json_text(response.text)
            
            # 3. å˜—è©¦è§£æ JSON
            data = json.loads(cleaned_text)
            return data

        except json.JSONDecodeError as e:
            cprint(f"âš ï¸ [Attempt {attempt+1}/{retries}] JSON è§£æå¤±æ•—: {e}", "yellow")
            # é€™è£¡å¯ä»¥åŠ ä¸€æ®µé‚è¼¯ï¼šå¦‚æœè§£æå¤±æ•—ï¼Œå†æ¬¡ä¸Ÿçµ¦ LLM å«å®ƒä¿®æ­£æ ¼å¼ (Auto-Repair)
            # ä½†ç‚ºäº†ç°¡å–®ï¼Œæˆ‘å€‘å…ˆé‡è©¦å°±å¥½
            
        except exceptions.ResourceExhausted:
            cprint(f"âš ï¸ [Attempt {attempt+1}/{retries}] Rate Limit (429). Cooling down...", "yellow")
            time.sleep(delay * 2 * (attempt + 1)) # æŒ‡æ•¸é€€é¿ï¼Œè¶Šç­‰è¶Šä¹…
            continue

        except Exception as e:
            cprint(f"âš ï¸ [Attempt {attempt+1}/{retries}] API Error: {e}", "yellow")
            
        # å¤±æ•—å¾Œä¼‘æ¯ä¸€ä¸‹å†è©¦
        time.sleep(delay)

    # å¦‚æœé‡è©¦æ¬¡æ•¸ç”¨å®Œé‚„æ˜¯å¤±æ•—
    cprint(f"âŒ API Call Failed after {retries} attempts.", "red")
    return default_output if default_output is not None else {}


    def fetch_relevant_history_resumes(jd_text, n_results=3):
        """
        æ ¹æ“šç›®å‰çš„ JDï¼Œå» History DB æ‰¾å‡ºæœ€ç›¸é—œçš„ N ä»½ã€Œéå»å±¥æ­·ã€ã€‚
        å›å‚³ï¼šä¸€å€‹åŒ…å«çµæ§‹åŒ–å±¥æ­·å…§å®¹çš„ Listã€‚
        """
        try:
            client = chromadb.PersistentClient(path=CHROMA_PATH)
            # æ³¨æ„ï¼šæˆ‘å€‘ä¹‹å‰æŠŠ Resume å­˜é€²äº† past_applications_jdsï¼Œä¸¦æ¨™è¨˜ doc_type="RESUME"
            collection = client.get_collection("past_applications_jds")
            
            # 1. èªæ„æœå°‹ï¼šæ‰¾è·Ÿé€™å€‹ JD æœ€åƒçš„ Resume
            results = collection.query(
                query_texts=[jd_text],
                n_results=n_results,
                where={"doc_type": "RESUME"} # åªæ‰¾å±¥æ­·ï¼Œä¸æ‰¾éå»çš„ JD æˆ– Cover Letter
            )
            
            retrieved_resumes = []
            
            for i, meta in enumerate(results['metadatas'][0]):
                # å–å¾—åŸå§‹æª”åä½œç‚º ID
                source_name = meta.get('filename', f"Resume_{i}")
                folder = meta.get('folder', 'Unknown')
                
                # æˆ‘å€‘åœ¨ ingest æ™‚æŠŠçµæ§‹åŒ–è³‡æ–™å­˜é€²äº† 'analysis_json' é€™å€‹ metadata æ¬„ä½
                json_str = meta.get('analysis_json', '{}')
                
                try:
                    struct_data = json.loads(json_str)
                    retrieved_resumes.append({
                        "source_id": f"{folder}/{source_name}", # æ¨™è¨˜ä¾†æºï¼Œæ–¹ä¾¿ Council æŒ‡è·¯
                        "content": struct_data
                    })
                except:
                    continue

            return retrieved_resumes

        except Exception as e:
            cprint(f"âš ï¸ History Retrieval Error: {e}", "red")
            return []